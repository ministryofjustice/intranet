apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: intranet-staging
  namespace: intranet-staging
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: intranet-staging
  minReplicas: 4
  maxReplicas: 12
  metrics:
    # fpm
    - type: ContainerResource
      containerResource:
        name: cpu
        container: fpm
        target:
          type: Utilization
          # If request is 500m let's early scale at 250m
          # Rely on CPU usage for scaling more than memory usage.
          # For scaling down, CPU settles quickly and memory is freed up slowly.
          averageUtilization: 50
    - type: ContainerResource
      containerResource:
        name: memory
        container: fpm
        target:
          type: Utilization
          # If request is 640Mi and php max is 384Mi let's scale at 512Mi
          averageUtilization: 80
    # nginx
    - type: ContainerResource
      containerResource:
        name: cpu
        container: nginx
        target:
          # If the request is cpu: 50m, let's scale at 30m
          # type: Utilization
          # averageUtilization: 60
          # Test out using AverageValue instead to mitigate duplicate logs as described in:
          # https://github.com/kubernetes/kube-state-metrics/issues/2403
          type: AverageValue
          averageValue: 30m
    - type: ContainerResource
      containerResource:
        name: memory
        container: nginx
        target:
          # If the request is memory: 100Mi, let's scale at 70Mi
          # type: Utilization
          # averageUtilization: 70
          # Test out using AverageValue instead to mitigate duplicate logs as described in:
          # https://github.com/kubernetes/kube-state-metrics/issues/2403
          type: AverageValue
          averageValue: 70Mi
